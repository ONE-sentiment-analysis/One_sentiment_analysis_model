{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5717b31",
   "metadata": {},
   "source": [
    "# One_sentiment_analysis_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c276cad",
   "metadata": {},
   "source": [
    "### Exploração e limpeza dos dados (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf4e4056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: nltk in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (3.9.2)\n",
      "Requirement already satisfied: spacy in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (3.8.11)\n",
      "Requirement already satisfied: scikit-learn in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: click in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from nltk) (8.3.1)\n",
      "Requirement already satisfied: joblib in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from nltk) (1.5.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from spacy) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from spacy) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from spacy) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from spacy) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from spacy) (0.20.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from spacy) (2.12.5)\n",
      "Requirement already satisfied: jinja2 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
      "Requirement already satisfied: wrapt in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ina/workspace/One_sentiment_analysis_model/.venv/lib/python3.13/site-packages (from jinja2->spacy) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# instalar os pacotes ncessarios no ambiente virtual\n",
    "%pip install pandas nltk spacy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22dd71db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pt-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "# baixa e instala o modelo small do spacy para português (tokenização, POS, lematização, etc.), que depois pode ser carregado com `spacy.load(\"pt_core_news_sm\")`.\n",
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05afc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset inicial? https://www.kaggle.com/datasets/augustop/portuguese-tweets-for-sentiment-analysis/data\n",
    "# este dataset foi baixado manualmente e colocado no diretorio `src/data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f0f93f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializacao das bibliotecas\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fa91a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>query_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>785809</th>\n",
       "      <td>1050705141207367680</td>\n",
       "      <td>Acordar 8 horas é tão bom :)</td>\n",
       "      <td>Fri Oct 12 11:10:01 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785810</th>\n",
       "      <td>1050706655049109504</td>\n",
       "      <td>@mayckcunha Olá, Mayck. Você já é cliente Clar...</td>\n",
       "      <td>Fri Oct 12 11:16:02 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785811</th>\n",
       "      <td>1050705846907392005</td>\n",
       "      <td>Opa tava na merda mm e fiquei logo mais feliz ...</td>\n",
       "      <td>Fri Oct 12 11:12:49 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785812</th>\n",
       "      <td>1050705490232127489</td>\n",
       "      <td>@andrebraga2806 Foi como a tua lealdade :)</td>\n",
       "      <td>Fri Oct 12 11:11:24 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785813</th>\n",
       "      <td>1050704920922521601</td>\n",
       "      <td>Feliz dia das crianças!! De hoje e de ontem......</td>\n",
       "      <td>Fri Oct 12 11:09:08 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "785809  1050705141207367680   \n",
       "785810  1050706655049109504   \n",
       "785811  1050705846907392005   \n",
       "785812  1050705490232127489   \n",
       "785813  1050704920922521601   \n",
       "\n",
       "                                               tweet_text  \\\n",
       "785809                       Acordar 8 horas é tão bom :)   \n",
       "785810  @mayckcunha Olá, Mayck. Você já é cliente Clar...   \n",
       "785811  Opa tava na merda mm e fiquei logo mais feliz ...   \n",
       "785812         @andrebraga2806 Foi como a tua lealdade :)   \n",
       "785813  Feliz dia das crianças!! De hoje e de ontem......   \n",
       "\n",
       "                            tweet_date sentiment query_used  \n",
       "785809  Fri Oct 12 11:10:01 +0000 2018  Positivo         :)  \n",
       "785810  Fri Oct 12 11:16:02 +0000 2018  Positivo         :)  \n",
       "785811  Fri Oct 12 11:12:49 +0000 2018  Positivo         :)  \n",
       "785812  Fri Oct 12 11:11:24 +0000 2018  Positivo         :)  \n",
       "785813  Fri Oct 12 11:09:08 +0000 2018  Positivo         :)  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregando o dataset original\n",
    "df = pd.read_csv('../data/NoThemeTweets.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "047999ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>query_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Tixaa23 14 para eu ir :)</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@drexalvarez O meu like eu já dei na época :)</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eu só queria conseguir comer alguma coisa pra ...</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:D que lindo dia !</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Primo_Resmungao Pq da pr jeito!!é uma \"oferta...</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text sentiment query_used\n",
       "0                          @Tixaa23 14 para eu ir :)  Positivo         :)\n",
       "1      @drexalvarez O meu like eu já dei na época :)  Positivo         :)\n",
       "2  Eu só queria conseguir comer alguma coisa pra ...  Positivo         :)\n",
       "3                                 :D que lindo dia !  Positivo         :)\n",
       "4  @Primo_Resmungao Pq da pr jeito!!é uma \"oferta...  Positivo         :)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removendo colunas desnessarias e limitando o dataset para 50.000 amostras\n",
    "df = df.drop([\"id\", \"tweet_date\"], axis=1)\n",
    "df = df[:50000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbc4bd5",
   "metadata": {},
   "source": [
    "### Transformação dos textos em números com TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba2ee656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converte colunas categóricas em valores inteiros com LabelEncoder:\n",
    "# mapeia cada rótulo de texto em um inteiro (ex.: 'Positivo' -> 0, 'Negativo' -> 1)\n",
    "lb = LabelEncoder()\n",
    "\n",
    "df[\"sentiment\"] = lb.fit_transform(df[\"sentiment\"])\n",
    "df[\"query_used\"] = lb.fit_transform(df[\"query_used\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6b8d92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb644b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text    0\n",
       "sentiment     0\n",
       "query_used    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificando se ha valores nulos no dataset\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ffa9d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega o modelo do spacy para portugues e cria o objeto `nlp` (tokenizador, POS, lematizador, dependências etc.). Esse `nlp` é usado para processar textos (ex.: `nlp(text)`).\n",
    "nlp = spacy.load(\"pt_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb0b64e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ina/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baixando recursos do nltk (se ainda nao tiverem sido baixados)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0111ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo as stop words em portugues\n",
    "stop_words = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b1fd357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizando os tweets com spacy\n",
    "tweets = df[\"tweet_text\"]\n",
    "tokenization = [nlp(text.lower()) for text in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "530b2a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     ../data/kaggle/working/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# baixando recursos do nltk (se ainda nao tiverem sido baixados) em um diretorio especifico\n",
    "nltk.download('wordnet', download_dir='../data/kaggle/working/nltk_data')\n",
    "nltk.data.path.append(\"../data/kaggle/working/nltk_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bb3a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# aplicando stemming e removendo stop words, pontuações, mentions e links\n",
    "new_tweets = []\n",
    "for phrase in tokenization:\n",
    "  new_phrase = \"\"\n",
    "  for token in phrase:\n",
    "    if not str(token) in stop_words and not token.is_punct and \"@\" not in str(token) and \"http\" not in str(token):\n",
    "      new_phrase += ps.stem(str(token)) + \" \"\n",
    "  new_tweets.append(new_phrase[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "720f60cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# atualizando a coluna tweet_text com os tweets processados\n",
    "df[\"tweet_text\"] = new_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef994ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>query_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14 ir</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>like dei época</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>queria conseguir comer alguma coisa pra poder ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d lindo dia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pq pr jeito!!é oferta ha q aproveitar :p</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  sentiment  query_used\n",
       "0                                              14 ir          1           1\n",
       "1                                     like dei época          1           1\n",
       "2  queria conseguir comer alguma coisa pra poder ...          1           1\n",
       "3                                        d lindo dia          1           1\n",
       "4           pq pr jeito!!é oferta ha q aproveitar :p          1           1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22141c31",
   "metadata": {},
   "source": [
    "### Treinamento de modelo supervisionado (ex.: Logistic Regression, Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7756dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando vetorizadores unigrama com CountVectorizer e TfidfVectorizer\n",
    "vect_uni_cv = CountVectorizer(ngram_range=(1,1), stop_words=stop_words)\n",
    "text_vect_uni_cv = vect_uni_cv.fit_transform(df[\"tweet_text\"])\n",
    "\n",
    "# dividindo os dados em treino e teste (80% treino, 20% teste)\n",
    "X_trainUCV, X_testUCV, y_trainUCV, y_testUCV = train_test_split(text_vect_uni_cv, df[\"sentiment\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# criando vetorizadores unigrama com TfidfVectorizer\n",
    "vect_uni_idf = TfidfVectorizer(ngram_range=(1,1), use_idf=True, norm='l2', stop_words=stop_words)\n",
    "text_vect_uni_idf = vect_uni_idf.fit_transform(df[\"tweet_text\"])\n",
    "\n",
    "# dividindo os dados em treino e teste (80% treino, 20% teste)\n",
    "X_trainUIDF, X_testUIDF, y_trainUIDF, y_testUIDF = train_test_split(text_vect_uni_idf, df[\"sentiment\"], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbb7c313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Count Vectorizer Random Forest: 99.99%\n"
     ]
    }
   ],
   "source": [
    "# treinando e avaliando o modelo Random Forest com CountVectorizer\n",
    "rfcUCV = RandomForestClassifier()\n",
    "\n",
    "rfcUCV.fit(X_trainUCV, y_trainUCV)\n",
    "y_predUCV = rfcUCV.predict(X_testUCV)\n",
    "\n",
    "acUCV = accuracy_score(y_testUCV, y_predUCV)\n",
    "\n",
    "print(f'Score Count Vectorizer Random Forest: {acUCV*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e75e817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score TFIDF Random Forest: 99.99%\n"
     ]
    }
   ],
   "source": [
    "# treinando e avaliando o modelo Random Forest com TfidfVectorizer\n",
    "rfcidf = RandomForestClassifier()\n",
    "\n",
    "rfcidf.fit(X_trainUIDF, y_trainUIDF)\n",
    "y_predidf = rfcidf.predict(X_testUIDF)\n",
    "\n",
    "acidf = accuracy_score(y_testUIDF, y_predidf)\n",
    "\n",
    "print(f'Score TFIDF Random Forest: {acidf*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8970c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Count Vectorizer Decision Tree Classifier: 99.95%\n"
     ]
    }
   ],
   "source": [
    "# treinando e avaliando o modelo Decision Tree com CountVectorizer\n",
    "dtrUVC = DecisionTreeClassifier()\n",
    "\n",
    "dtrUVC.fit(X_trainUCV, y_trainUCV)\n",
    "\n",
    "acUCV = dtrUVC.score(X_testUCV, y_testUCV)\n",
    "\n",
    "print(f'Score Count Vectorizer Decision Tree Classifier: {acUCV*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9882a51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score TFIDF Decision Tree Classifier: 99.76%\n"
     ]
    }
   ],
   "source": [
    "# treinando e avaliando o modelo Decision Tree com TfidfVectorizer\n",
    "dtridf = DecisionTreeClassifier()\n",
    "\n",
    "dtridf.fit(X_trainUIDF, y_trainUIDF)\n",
    "\n",
    "acidf = dtridf.score(X_testUCV, y_testUCV)\n",
    "\n",
    "print(f'Score TFIDF Decision Tree Classifier: {acidf*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fee5b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Count Vectorizer Naive Bayes: 99.80%\n"
     ]
    }
   ],
   "source": [
    "# treinando e avaliando o modelo usando Naive Bayes com CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnbUCV = MultinomialNB()\n",
    "mnbUCV.fit(X_trainUCV, y_trainUCV)\n",
    "y_predNB = mnbUCV.predict(X_testUCV)\n",
    "acNB = accuracy_score(y_testUCV, y_predNB)\n",
    "print(f'Score Count Vectorizer Naive Bayes: {acNB*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9a92a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score TFIDF Naive Bayes: 99.99%\n"
     ]
    }
   ],
   "source": [
    "# treinando e avaliando o modelo usando Naive Bayes com TfidfVectorizer\n",
    "mnbIDF = MultinomialNB()\n",
    "mnbIDF.fit(X_trainUIDF, y_trainUIDF)\n",
    "y_predNBIDF = mnbIDF.predict(X_testUIDF)\n",
    "acNBIDF = accuracy_score(y_testUIDF, y_predNBIDF)\n",
    "print(f'Score TFIDF Naive Bayes: {acNBIDF*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeafe02",
   "metadata": {},
   "source": [
    "### Métricas de desempenho (Acurácia, Precisão, Recall, F1-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001537b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d1d8f2",
   "metadata": {},
   "source": [
    "### Serialização do modelo (joblib/pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36c5d9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializacao do modelo treinado com Random Forest e CountVectorizer usando pickle para uso posterior sem necessidade de re-treinamento\n",
    "import pickle\n",
    "with open('../models/rfcUCV_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rfcUCV, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fe2a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializacao do modelo treinado com Random Forest e TfidfVectorizer usando pickle para uso posterior sem necessidade de re-treinamento\n",
    "with open('../models/rfcUIDF_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rfcidf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b890b7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializacao do modelo treinado com Decision Tree e CountVectorizer usando pickle para uso posterior sem necessidade de re-treinamento\n",
    "with open('../models/dtrUCV_model.pkl', 'wb') as f:\n",
    "    pickle.dump(dtrUVC, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00bda92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializacao do modelo treinado com Decision Tree e TfidfVectorizer usando pickle para uso posterior sem necessidade de re-treinamento\n",
    "with open('../models/dtrUIDF_model.pkl', 'wb') as f:\n",
    "    pickle.dump(dtridf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86061c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializacao do modelo treinado com Naive Bayes e CountVectorizer usando pickle para uso posterior sem necessidade de re-treinamento\n",
    "with open('../models/mnbUCV_model.pkl', 'wb') as f:\n",
    "    pickle.dump(mnbUCV, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3c220da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializacao do modelo treinado com Naive Bayes e CountVectorizer usando pickle para uso posterior sem necessidade de re-treinamento\n",
    "with open('../models/mnbUCV_model.pkl', 'wb') as f:\n",
    "    pickle.dump(mnbUCV, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
